{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04567b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# استيراد المكتبات\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "# قراءة البيانات\n",
    "df = pd.read_csv(\"heart_2022_no_nans.csv\")\n",
    "\n",
    "# ترميز الأعمدة النصية لتحديد أهمية الخصائص\n",
    "df_encoded = df.copy()\n",
    "for col in df_encoded.select_dtypes(include='object').columns:\n",
    "    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col].astype(str))\n",
    "\n",
    "# فصل البيانات إلى ميزات وهدف\n",
    "X = df_encoded.drop('HadHeartAttack', axis=1)\n",
    "y = df_encoded['HadHeartAttack']\n",
    "\n",
    "# تدريب نموذج لتحديد أهمية الأعمدة\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y)\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "top_25 = importances.sort_values(ascending=False).head(25)\n",
    "print(\"Top 25 Important Features:\\n\", top_25)\n",
    "\n",
    "# الأعمدة الأهم (تمت إضافة Sex)\n",
    "important_cols = [\n",
    "    'HadAngina', 'BMI', 'State', 'WeightInKilograms', 'HeightInMeters',\n",
    "    'AgeCategory', 'SleepHours', 'PhysicalHealthDays', 'TetanusLast10Tdap',\n",
    "    'GeneralHealth', 'MentalHealthDays', 'RemovedTeeth', 'SmokerStatus',\n",
    "    'HadStroke', 'RaceEthnicityCategory', 'HadDiabetes', 'ChestScan',\n",
    "    'CovidPos', 'ECigaretteUsage', 'FluVaxLast12', 'HadHeartAttack',\n",
    "    'AlcoholDrinkers', 'Sex'  # تمت إضافة Sex هنا\n",
    "]\n",
    "\n",
    "# تصفية البيانات على الأعمدة المهمة\n",
    "df_filtered = df[important_cols]\n",
    "\n",
    "# موازنة البيانات (نفس عدد \"Yes\" و\"No\")\n",
    "sample_size = 13435\n",
    "yes_sample = df_filtered[df_filtered[\"HadHeartAttack\"] == \"Yes\"].sample(n=sample_size, random_state=42)\n",
    "no_sample = df_filtered[df_filtered[\"HadHeartAttack\"] == \"No\"].sample(n=sample_size, random_state=42)\n",
    "\n",
    "balanced_data = pd.concat([yes_sample, no_sample])\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# إعداد البيانات النهائية\n",
    "df = balanced_data\n",
    "X = df.drop(\"HadHeartAttack\", axis=1)\n",
    "y = df[\"HadHeartAttack\"]\n",
    "\n",
    "# تقسيم البيانات\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# تحديد الأعمدة الفئوية والرقمية\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(exclude='object').columns.tolist()\n",
    "\n",
    "# بايبلاين الأعمدة الرقمية\n",
    "numerical_pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# بايبلاين الأعمدة الفئوية\n",
    "categorical_pipe = Pipeline([\n",
    "    ('encoder', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# دمج المعالجات\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numerical_pipe', numerical_pipe, numerical_cols),\n",
    "    ('categorical_pipe', categorical_pipe, categorical_cols)\n",
    "])\n",
    "\n",
    "# تجهيز البيانات للتدريب\n",
    "x_train_prep = preprocessor.fit_transform(x_train)\n",
    "x_test_prep = preprocessor.transform(x_test)\n",
    "\n",
    "# ضبط معاملات RandomForest\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# تنفيذ البحث\n",
    "random_search.fit(x_train_prep, y_train)\n",
    "print(\"Best Parameters:\\n\", random_search.best_params_)\n",
    "\n",
    "# تدريب النموذج النهائي (حسب أفضل المعاملات أو بشكل يدوي)\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=4,\n",
    "    max_features='sqrt',\n",
    "    max_depth=40,\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(x_train_prep, y_train)\n",
    "\n",
    "# التقييم\n",
    "y_pred = model.predict(x_test_prep)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# حفظ النموذج والمعالج\n",
    "joblib.dump(model, \"model.pkl\")\n",
    "joblib.dump(preprocessor, \"preprocessor.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
